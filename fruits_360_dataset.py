# -*- coding: utf-8 -*-
"""Fruits_360_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16FW1s6MUFlVHFZQp1PfimG4KwYIgefnR
"""

!pip install kaggle

!ls

!mkdir .kaggle

import json
token = {"username":".......", "key":"........"}
with open('/content/.kaggle/kaggle.json', 'w') as file:
  json.dump(token, file)

!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json

!kaggle config set -n path -v{/content}

!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets list

!kaggle datasets list -s Fruits

!kaggle datasets download -d moltean/fruits -p /content

!unzip \*.zip

!ls

!cd fruits-360_dataset

!cd fruits-360_dataset/fruits-360/

!cd fruits-360_dataset/fruits-360/Training/

!ls

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from keras import *
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.optimizers import Adam
from keras.layers.normalization import BatchNormalization
from keras.utils import np_utils
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D
#from keras.layers.advanced_activations import LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
#from sklearn.model_selection import train_test_split
from skimage import io
import os
import scipy.misc
# from scipy.misc import imread, imresize
from keras import regularizers
import csv
from urllib.request import urlopen, urlretrieve
from PIL import Image
from tqdm import tqdm_notebook
from sklearn.utils import shuffle
from sklearn.datasets import load_files
from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint

import cv2

def load_images(path):
    img_data = []
    labels = []
    idx_to_label = []
    i = -1
    for fruit in os.listdir(path): 
        fruit_path = os.path.join(path,fruit)
        labels.append(fruit)
        i = i+1
        for img in os.listdir(fruit_path):
            img_path = os.path.join(fruit_path,img)
            image = cv2.imread(img_path)
            image = cv2.resize(image, (64, 64))
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            img_data.append(image)
            idx_to_label.append(i)
    return np.array(img_data),np.array(idx_to_label),labels

train_data_path = 'fruits-360_dataset/fruits-360/Training'
val_data_path = 'fruits-360_dataset/fruits-360/Test'
X_train,y_train,label_data = load_images(train_data_path)
print('shape of X_train is:', X_train.shape)
print('shape of y_train is:', y_train.shape)
print(label_data)
X_test,y_test,label_data_garbage = load_images(val_data_path)
print('shape of X_test is:', X_test.shape)
print('shape of y_test is:', y_test.shape)

print('number of classes:', len(label_data))

import cv2 as cv
im = cv.imread(fruits-360_dataset/fruits-360/Training.jpg)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
img = plt.imshow(X_train[0])

print('The label is:', y_train[0])

import keras           
num_classes = 120
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train = X_train / 255
X_test = X_test / 255

model = Sequential()

model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu', padding = 'same', input_shape = (64, 64, 3)))
model.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))
model.add(MaxPooling2D(pool_size = (2, 2)))
model.add(Dropout(0.3))

model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))
model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))
model.add(MaxPooling2D(pool_size = (2, 2)))
model.add(Dropout(0.3))

model.add(Flatten())
model.add(Dense(512, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(120, activation = 'softmax'))

model.summary()

model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = (X_test, y_test))

model.fit(X_train, y_train, batch_size = 32, epochs = 1, validation_data = (X_test, y_test))

model.fit(X_train, y_train, batch_size = 32, epochs = 2, validation_data = (X_test, y_test))

model.evaluate(X_test, y_test)[1]



num_classes = 120

base_model = applications.resnet50.ResNet50(weights = None, include_top = False, input_shape = (64, 64, 3))

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.7)(x)
predictions = Dense(num_classes, activation = 'softmax')(x)
model = Model(inputs= base_model.input, outputs = predictions)

adam = Adam(lr = 0.0001)
model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])

model.fit(X_train, y_train, epochs = 10, batch_size = 64)

preds = model.evaluate(X_test, y_test)
print("Loss = " + str(preds[0]))
print("Test Accuracy = " + str(preds[1]))